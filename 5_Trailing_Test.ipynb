{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9RdBj3kiSM0d2G+PE/GTF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSGh7qV6-Ei2"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MTaD4hWW-Swf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 데이터 호출\n",
        "data_test_tmp = pd.read_csv(\"/kaggle/input/data-set-plus-test-24-08-07/SOL_Data_Test_Indicator3.csv\")\n",
        "\n",
        "# Display the first few rows of the dataset to ensure it is loaded correctly\n",
        "data_test_tmp.head()"
      ],
      "metadata": {
        "id": "N4rceCji-VNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = data_test_tmp\n",
        "data_test.columns"
      ],
      "metadata": {
        "id": "_D-mT8yM-Y-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = data_test.drop(columns=['Unnamed: 0'])"
      ],
      "metadata": {
        "id": "5v7KHCiV-c3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open_time 열을 datetime 형식으로 변환\n",
        "if not np.issubdtype(data_test['open_time'].dtype, np.datetime64):\n",
        "    data_test['open_time'] = pd.to_datetime(data_test['open_time'])\n",
        "\n",
        "# time 열을 분 단위로 변환\n",
        "data_test['time'] = data_test['open_time'].dt.hour * 60 + data_test['open_time'].dt.minute"
      ],
      "metadata": {
        "id": "CygaFLKW-eXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용하지 않을 열 제외\n",
        "data_test_predict = data_test.drop(columns=['open_time', 'max_return_60min', 'min_return_60min'])"
      ],
      "metadata": {
        "id": "Xi0I-ohO-iRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용하지 않을 열 제외 v2\n",
        "# 피처 목록\n",
        "features_to_keep = ['ichimoku_conversion_9', 'ichimoku_conversion_200', 'supertrend_upper_14_2_10',\n",
        "                    'supertrend_upper_10_3_20', 'bollinger_hband_200', 'volume_ma_100', 'ROC_30',\n",
        "                    'open', 'high', 'supertrend_lower_10_3_20', 'obv', 'atr_50', 'volume_ma_200',\n",
        "                    'Accumulation_Distribution_Line', 'bollinger_lband_20', 'lowerband', 'volume_ma_20',\n",
        "                    'supertrend_lower_7_3_14', 'atr_14', 'disparity_index_100', 'price_ma_200',\n",
        "                    'bollinger_lband_50', 'ichimoku_conversion_52', 'upperband', 'atr_20', 'price_ma_20',\n",
        "                    'disparity_index_20', 'time', 'vwap', 'bollinger_lband_200', 'atr_10', 'MFI_40',\n",
        "                    'volume_ma_10', 'supertrend_in_uptrend_7_3_14', 'Momentum_30', 'Momentum_20',\n",
        "                    'supertrend_upper_20_4_50', 'bollinger_hband_100', 'MFI_50', 'CMO_50', 'close',\n",
        "                    'Momentum_50', 'stoch_%k_21_5', 'supertrend_upper_7_3_14', 'bollinger_hband_50',\n",
        "                    'Parabolic_SAR_0.02', 'bollinger_lband_100', 'stoch_%k_9_3', 'Williams_%R_30', 'CMO_40']\n",
        "\n",
        "# 피처들만 남기기\n",
        "data_test_predict = data_test[features_to_keep]"
      ],
      "metadata": {
        "id": "jV-N6gGC-kTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 무한대 값을 NaN으로 대체\n",
        "data_test_predict.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# NaN 값을 평균으로 대체\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data_test_predict_imputed = imputer.fit_transform(data_test_predict)  # 같은 imputer 사용\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = MinMaxScaler()\n",
        "data_test_predict_scaled = scaler.fit_transform(data_test_predict_imputed)  # 같은 scaler 사용"
      ],
      "metadata": {
        "id": "zP5diDuq-mmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######################\n",
        "\n",
        "**Transformer 모델 로드**\n",
        "######################"
      ],
      "metadata": {
        "id": "nIiRKhRJ-4Sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformer model 호출\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# 모델 정의 (로드할 때 필요)\n",
        "class TransformerEncoderModel(nn.Module):\n",
        "    def __init__(self, input_dim, nhead, num_layers, dim_feedforward, output_dim):\n",
        "        super(TransformerEncoderModel, self).__init__()\n",
        "        self.embedding = nn.Linear(input_dim, input_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, src):\n",
        "        src = self.embedding(src)\n",
        "        output = self.transformer_encoder(src)\n",
        "        output = self.fc(output[:, -1, :])  # Use the output from the last time step\n",
        "        return output"
      ],
      "metadata": {
        "id": "-8OlfMyK-o86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformer model 호출2\n",
        "# 시퀀스 길이 설정\n",
        "sequence_length = 60\n",
        "\n",
        "# 예측 데이터를 시퀀스 형태로 변환\n",
        "def create_sequences_for_prediction(data, sequence_length):\n",
        "    sequences = []\n",
        "    for i in range(len(data) - sequence_length + 1):\n",
        "        seq = data[i:i + sequence_length]\n",
        "        sequences.append(seq)\n",
        "    return np.array(sequences)\n",
        "\n",
        "# 예측용 시퀀스 데이터 생성\n",
        "X_test_seq = create_sequences_for_prediction(data_test_predict_scaled, sequence_length)\n",
        "\n",
        "# 입력 차원 확인 및 설정\n",
        "input_dim = X_test_seq.shape[2]\n",
        "print(f\"Input dimension: {input_dim}\")\n",
        "\n",
        "# 모델 설정 (로드할 때 필요)\n",
        "nhead = 2\n",
        "num_layers = 2\n",
        "dim_feedforward = 64\n",
        "output_dim = 1\n",
        "\n",
        "model = TransformerEncoderModel(input_dim, nhead, num_layers, dim_feedforward, output_dim)\n",
        "\n",
        "# 모델 로드\n",
        "model_path = '/kaggle/input/lstm_indiactor3/pytorch/tcn_transformer/6/SOL60_SMALLL_INDICATOR3_Transformer_v3.pth'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()\n",
        "print(f\"Model loaded from {model_path}\")"
      ],
      "metadata": {
        "id": "Teh77rFu-wTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######################\n",
        "\n",
        "TCN 모델 로드\n",
        "\n",
        "######################"
      ],
      "metadata": {
        "id": "NS5jRSTi--wA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TCN 모델 호출\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "#모델 로드\n",
        "class TCNModel(nn.Module):\n",
        "    def __init__(self, input_channels, num_channels, kernel_size=2, dropout=0.2):\n",
        "        super(TCNModel, self).__init__()\n",
        "        self.tcn = nn.Conv1d(input_channels, num_channels, kernel_size, padding=kernel_size//2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(num_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)  # (batch_size, seq_len, input_channels) -> (batch_size, input_channels, seq_len)\n",
        "        y1 = self.tcn(x)\n",
        "        y1 = self.relu(y1)\n",
        "        y1 = self.dropout(y1)\n",
        "        y1 = y1[:, :, -1]\n",
        "        o = self.fc(y1)\n",
        "        return o"
      ],
      "metadata": {
        "id": "I4uHW4Xr_AsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TCN 모델 호출2\n",
        "# 시퀀스 길이 설정\n",
        "sequence_length = 60\n",
        "\n",
        "# 예측 데이터를 시퀀스 형태로 변환\n",
        "def create_sequences_for_prediction(data, sequence_length):\n",
        "    sequences = []\n",
        "    for i in range(len(data) - sequence_length + 1):\n",
        "        seq = data[i:i + sequence_length]\n",
        "        sequences.append(seq)\n",
        "    return np.array(sequences)\n",
        "\n",
        "# 예측용 시퀀스 데이터 생성\n",
        "X_test_seq = create_sequences_for_prediction(data_test_predict_scaled, sequence_length)\n",
        "\n",
        "# 입력 차원 확인 및 설정\n",
        "input_channels = X_test_seq.shape[2]\n",
        "print(f\"Input channels: {input_channels}\")\n",
        "\n",
        "# 모델 설정\n",
        "num_channels = 64\n",
        "model = TCNModel(input_channels, num_channels)\n",
        "\n",
        "# 모델 로드\n",
        "model_path = '/kaggle/input/lstm_indiactor3/pytorch/tcn_transformer/9/SOL60_SMALLL_INDICATOR3_TCN_v4_180_11.pth'\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()\n",
        "print(f\"Model loaded from {model_path}\")"
      ],
      "metadata": {
        "id": "XG9F4yrd_F90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######################\n",
        "\n",
        "예측 수행\n",
        "\n",
        "######################"
      ],
      "metadata": {
        "id": "4oq5zzlS_TYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 슬라이딩 윈도우로 데이터 범위 추출\n",
        "num_rows = data_test_predict_scaled.shape[0]\n",
        "\n",
        "# 시퀀스 데이터를 텐서로 변환\n",
        "X_test_tensor = torch.tensor(X_test_seq, dtype=torch.float32)\n",
        "print(f\"Tensor Transform Complete\")"
      ],
      "metadata": {
        "id": "-YkjIYJC_Jyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 GPU로 이동 (가능한 경우)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "X_test_tensor = X_test_tensor.to(device)"
      ],
      "metadata": {
        "id": "dgsJpYxs_KRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction 결과 저장\n",
        "results = []\n",
        "\n",
        "#window_size = 216000\n",
        "#window_size = 259200\n",
        "window_size = 302400\n",
        "\n",
        "batch_size = 63  # 배치 크기 설정\n",
        "\n",
        "for end in tqdm(range(num_rows, window_size - 1, -batch_size)):\n",
        "    start = max(end - batch_size + 1, 0)\n",
        "\n",
        "    # 해당 범위에 대한 시퀀스 텐서 추출\n",
        "    X_test_tensor_tmp = X_test_tensor[start:end]\n",
        "\n",
        "    # 예측 수행\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = torch.sigmoid(model(X_test_tensor_tmp)).squeeze().cpu().numpy()\n",
        "\n",
        "    # 예측 결과를 이진 분류로 변환 (0 또는 1)\n",
        "    predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "    # 예측 결과의 마지막 값을 추가\n",
        "    if len(predictions.shape) > 0:\n",
        "        results.append(predictions[-1])\n",
        "    else:\n",
        "        results.append(predictions)\n",
        "\n",
        "results = results[::-1]  # 원래 순서대로 변경"
      ],
      "metadata": {
        "id": "n2ei1JMf_Llt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과를 원본 데이터프레임에 추가\n",
        "data_test['Predictions'] = np.nan\n",
        "data_test.loc[data_test.index[-len(results):], 'Predictions'] = results\n",
        "data_test = data_test.dropna(subset=['Predictions'])"
      ],
      "metadata": {
        "id": "g6N3TAjw_OUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'max_return_60min' 값이 1 이상이고 'prediction' 값이 0인 데이터의 개수\n",
        "count_max_return_ge_1_prediction_0 = len(data_test[(data_test['max_return_60min'] >= 1.1) & (data_test['Predictions'] == 1)])\n",
        "\n",
        "# 'max_return_60min' 값이 1 미만이고 'prediction' 값이 1인 데이터의 개수\n",
        "count_max_return_lt_1_prediction_1 = len(data_test[(data_test['max_return_60min'] < 1.1) & (data_test['Predictions'] == 0)])\n",
        "\n",
        "#\n",
        "print(f\"max_return_60min이 1.1 이상인데 prediction이 1인 데이터의 비율: {count_max_return_ge_1_prediction_0/len(data_test)*100}\")\n",
        "print(f\"max_return_60min이 1.1 미만인데 prediction이 0인 데이터의 비율: {count_max_return_lt_1_prediction_1/len(data_test)*100}\")"
      ],
      "metadata": {
        "id": "Cf5tjR0H_P9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######################\n",
        "\n",
        "시간대 분석\n",
        "\n",
        "######################"
      ],
      "metadata": {
        "id": "AYX-jhZK_adp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 시간대를 나타내는 새로운 열 추가 (30분 단위)\n",
        "data_test['half_hour'] = data_test['open_time'].dt.floor('30T').dt.time\n",
        "\n",
        "# 시간대별로 데이터 그룹화 (30분 단위)\n",
        "grouped = data_test.groupby('half_hour')\n",
        "\n",
        "# 각 시간대별로 조건을 만족하는 데이터의 개수를 계산하는 함수\n",
        "def calculate_counts(group):\n",
        "    count_max_return_ge_1_prediction_0 = len(group[(group['max_return_60min'] >= 1.1) & (group['Predictions'] == 1)])\n",
        "    count_max_return_lt_1_prediction_1 = len(group[(group['max_return_60min'] < 1.1) & (group['Predictions'] == 0)])\n",
        "\n",
        "    total_count = len(group)\n",
        "\n",
        "    if total_count == 0:\n",
        "        return pd.Series([0, 0, 0, 0, 0])\n",
        "\n",
        "    rate_max_return_ge_1_prediction_0 = (count_max_return_ge_1_prediction_0 / total_count) * 100\n",
        "    rate_max_return_lt_1_prediction_1 = (count_max_return_lt_1_prediction_1 / total_count) * 100\n",
        "\n",
        "    total_rate = rate_max_return_ge_1_prediction_0 + rate_max_return_lt_1_prediction_1\n",
        "\n",
        "    return pd.Series([count_max_return_ge_1_prediction_0, count_max_return_lt_1_prediction_1, rate_max_return_ge_1_prediction_0, rate_max_return_lt_1_prediction_1, total_rate])\n",
        "\n",
        "# 각 그룹에 함수 적용\n",
        "results = grouped.apply(calculate_counts)\n",
        "results.columns = ['Count_GE_1_Pred_0', 'Count_LT_1_Pred_1', 'Rate_GE_1_Pred_0', 'Rate_LT_1_Pred_1', 'Total_Rate']\n",
        "\n",
        "# 결과 출력\n",
        "print(results)"
      ],
      "metadata": {
        "id": "HUsmnA7S_XQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시간대를 UTC 및 KST로 표시\n",
        "results['half_hour_utc'] = pd.to_datetime(results.index.astype(str), format='%H:%M:%S').time\n",
        "results['half_hour_kst'] = (pd.to_datetime(results.index.astype(str), format='%H:%M:%S') + pd.Timedelta(hours=9)).time\n",
        "results['half_hour_label'] = results.index.astype(str) + ' (' + results['half_hour_kst'].astype(str) + ' KST)'\n",
        "\n",
        "# x축을 시간으로, y축을 Total_Rate으로 하는 차트 그리기\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(results['half_hour_label'], results['Total_Rate'], marker='o')\n",
        "plt.xlabel('Half Hour of the Day (UTC)')\n",
        "plt.ylabel('Total Rate (%)')\n",
        "plt.title('Total Rate of Conditions Met by Half Hour of the Day (UTC with KST)')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45, ha='right')  # 레이블을 오른쪽으로 회전하여 수평으로 정렬\n",
        "\n",
        "# y축 90 라인 진하게 표시\n",
        "plt.axhline(90, color='red', linewidth=1.5, linestyle='--')  # y=90 라인을 진하게\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2QQk9H7r_ehq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시간대를 나타내는 새로운 열 추가 (30분 단위)\n",
        "data_test['half_hour'] = data_test['open_time'].dt.floor('30T').dt.time\n",
        "\n",
        "# 시간대별로 데이터 그룹화 (30분 단위)\n",
        "grouped = data_test.groupby('half_hour')\n",
        "\n",
        "# 각 시간대별로 max_return_60min이 1.1 이상이고 Predictions가 1인 값의 비율을 계산하는 함수\n",
        "def calculate_ratio(group):\n",
        "    count_condition_met = len(group[(group['max_return_60min'] >= 1.1) & (group['Predictions'] == 1)])\n",
        "    total_count = len(group)\n",
        "\n",
        "    if total_count == 0:\n",
        "        return 0\n",
        "\n",
        "    return (count_condition_met / total_count) * 100\n",
        "\n",
        "# 각 그룹에 함수 적용\n",
        "results = grouped.apply(calculate_ratio)\n",
        "results = results.reset_index()\n",
        "results.columns = ['half_hour', 'Condition_Met_Ratio']\n",
        "\n",
        "# 결과 출력\n",
        "print(results)"
      ],
      "metadata": {
        "id": "082Qgowz_hGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시간대를 UTC 및 KST로 표시\n",
        "results['half_hour'] = pd.to_datetime(results['half_hour'].astype(str), format='%H:%M:%S').dt.strftime('%H:%M')\n",
        "results['half_hour_kst'] = (pd.to_datetime(results['half_hour'], format='%H:%M') + pd.Timedelta(hours=9)).dt.strftime('%H:%M')\n",
        "results['half_hour_label'] = results['half_hour'] + ' (' + results['half_hour_kst'] + ' KST)'\n",
        "\n",
        "# x축을 시간으로, y축을 Condition_Met_Ratio로 하는 차트 그리기\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(results['half_hour_label'], results['Condition_Met_Ratio'], marker='o')\n",
        "plt.xlabel('Half Hour of the Day (UTC)')\n",
        "plt.ylabel('Condition Met Ratio (%)')\n",
        "plt.title('Ratio of max_return_60min >= 1.1 and Predictions == 1 by Half Hour (UTC with KST)')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45, ha='right')  # 레이블을 오른쪽으로 회전하여 수평으로 정렬\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RvmyprJz_nlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "######################\n",
        "\n",
        "시간대 분석2\n",
        "\n",
        "######################\n",
        "\n"
      ],
      "metadata": {
        "id": "bJdAmDPAAR-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'open_time' to datetime if it's not already\n",
        "data_test['open_time'] = pd.to_datetime(data_test['open_time'])\n",
        "\n",
        "# Add a new column representing half-hour intervals\n",
        "data_test['half_hour'] = data_test['open_time'].dt.floor('30T').dt.time\n",
        "\n",
        "# Group by the half-hour intervals\n",
        "grouped = data_test.groupby('half_hour')\n",
        "\n",
        "# Define the function to calculate the counts and rates\n",
        "def calculate_counts(group):\n",
        "    count_max_return_ge_1_prediction_0 = len(group[(group['max_return_60min'] >= 1.1) & (group['Predictions'] == 1)])\n",
        "    count_max_return_lt_1_prediction_1 = len(group[(group['max_return_60min'] < 1.1) & (group['Predictions'] == 0)])\n",
        "\n",
        "    total_count = len(group)\n",
        "\n",
        "    if total_count == 0:\n",
        "        return pd.Series([0, 0, 0, 0, 0])\n",
        "\n",
        "    rate_max_return_ge_1_prediction_0 = (count_max_return_ge_1_prediction_0 / total_count) * 100\n",
        "    rate_max_return_lt_1_prediction_1 = (count_max_return_lt_1_prediction_1 / total_count) * 100\n",
        "\n",
        "    total_rate = rate_max_return_ge_1_prediction_0 + rate_max_return_lt_1_prediction_1\n",
        "\n",
        "    return pd.Series([count_max_return_ge_1_prediction_0, count_max_return_lt_1_prediction_1, rate_max_return_ge_1_prediction_0, rate_max_return_lt_1_prediction_1, total_rate])\n",
        "\n",
        "# Apply the function to the grouped data\n",
        "results = grouped.apply(calculate_counts)\n",
        "results.columns = ['Count_GE_1_Pred_0', 'Count_LT_1_Pred_1', 'Rate_GE_1_Pred_0', 'Rate_LT_1_Pred_1', 'Total_Rate']\n",
        "\n",
        "# Function to calculate the ratio for condition met\n",
        "def calculate_ratio(group):\n",
        "    count_condition_met = len(group[(group['max_return_60min'] >= 1.1) & (group['Predictions'] == 1)])\n",
        "    total_count = len(group)\n",
        "\n",
        "    if total_count == 0:\n",
        "        return 0\n",
        "\n",
        "    return (count_condition_met / total_count) * 100\n",
        "\n",
        "# Apply the function to the grouped data\n",
        "ratio_results = grouped.apply(calculate_ratio)\n",
        "ratio_results = ratio_results.reset_index()\n",
        "ratio_results.columns = ['half_hour', 'Condition_Met_Ratio']\n",
        "\n",
        "# Combine the results into a single DataFrame\n",
        "combined_results = results.reset_index()\n",
        "combined_results['Condition_Met_Ratio'] = ratio_results['Condition_Met_Ratio']\n",
        "\n",
        "# 시간대를 UTC 및 KST로 표시\n",
        "combined_results['half_hour_utc'] = pd.to_datetime(combined_results['half_hour'].astype(str), format='%H:%M:%S').dt.strftime('%H:%M')\n",
        "combined_results['half_hour_kst'] = (pd.to_datetime(combined_results['half_hour_utc'], format='%H:%M') + pd.Timedelta(hours=9)).dt.strftime('%H:%M')\n",
        "combined_results['half_hour_label'] = combined_results['half_hour_utc'] + ' (' + combined_results['half_hour_kst'] + ' KST)'"
      ],
      "metadata": {
        "id": "Re8ofHem_pPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the combined results\n",
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "ax1.plot(combined_results['half_hour_label'], combined_results['Total_Rate'], marker='o', color='b', label='Total Rate')\n",
        "ax1.set_xlabel('Half Hour of the Day (UTC)')\n",
        "ax1.set_ylabel('Total Rate (%)', color='b')\n",
        "ax1.tick_params(axis='y', labelcolor='b')\n",
        "ax1.grid(True)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(combined_results['half_hour_label'], combined_results['Condition_Met_Ratio'], marker='o', color='g', label='Condition Met Ratio')\n",
        "ax2.set_ylabel('Condition Met Ratio (%)', color='g')\n",
        "ax2.tick_params(axis='y', labelcolor='g')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.title('Comparison of Total Rate and Condition Met Ratio by Half Hour (UTC with KST)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PMLUvqAE_rsH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}